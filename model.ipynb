{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m3llad0/TC3007C/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SxG3O1cjkvjR"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization , MaxPooling2D, Conv2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "DoWM_d5gkvjV",
        "outputId": "9f36bed8-bed5-4660-a941-8ac0f7b2437b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/root/.kaggle/': Not a directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-047cdeab89b8>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle datasets download -d mohamedhanyyy/chest-ctscan-images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chest-ctscan-images.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzipObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m    \u001b[0;31m# Extract all the contents of zip file in current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[0mzipObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chest-ctscan-images.zip'"
          ]
        }
      ],
      "source": [
        "#Download the dataset from kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d mohamedhanyyy/chest-ctscan-images\n",
        "\n",
        "with ZipFile('chest-ctscan-images.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "\n",
        "!rm chest-ctscan-images.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXsLuFuAkvjX"
      },
      "source": [
        "## Preprocesamiento de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = './Data/train'\n",
        "test_data_dir = './Data/test'\n",
        "validation_data_dir = './Data/valid'"
      ],
      "metadata": {
        "id": "MCnkLkTWTmk3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (224, 460)\n",
        "\n",
        "training_datagen = ImageDataGenerator(dtype='float32',)\n",
        "test_datagen = ImageDataGenerator( dtype='float32')\n",
        "validation_datagen = ImageDataGenerator( dtype='float32')\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load and preprocess testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load and preprocess validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=input_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3uf0GXkTwzf",
        "outputId": "0ad4495f-64c1-42f8-dac4-aee6a241b5a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 613 images belonging to 4 classes.\n",
            "Found 315 images belonging to 4 classes.\n",
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción del modelo\n",
        "\n",
        "El modelo se construyó utilizando como base\n"
      ],
      "metadata": {
        "id": "kEPxqPjIprvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "base_model = ResNet50(include_top=False,\n",
        "                      pooling='avg',\n",
        "                      weights='imagenet',\n",
        "                      input_shape = (224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  if 'conv5' not in layer.name:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "WnYWwsQ0T8Tg",
        "outputId": "bec64aa2-e179-4f00-c297-0961ea927e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow.keras.models.Sequential()\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "skV6gXXJUD4x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uZ_BpyFQV0uD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(verbose = 1,\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True)\n",
        "epochs = 100\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    verbose = 1,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dw1zi5iUIiM",
        "outputId": "f858c124-80e9-442f-9b97-1663930e269e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "39/39 [==============================] - 902s 23s/step - loss: 1.0753 - accuracy: 0.6949 - val_loss: 119.9690 - val_accuracy: 0.1806\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 856s 22s/step - loss: 0.3090 - accuracy: 0.8972 - val_loss: 435.8243 - val_accuracy: 0.1806\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 851s 22s/step - loss: 0.2482 - accuracy: 0.9347 - val_loss: 12.4046 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 821s 21s/step - loss: 0.1942 - accuracy: 0.9364 - val_loss: 2.4959 - val_accuracy: 0.6944\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 833s 21s/step - loss: 0.1054 - accuracy: 0.9625 - val_loss: 2.1404 - val_accuracy: 0.7222\n",
            "Epoch 6/100\n",
            "12/39 [========>.....................] - ETA: 9:02 - loss: 0.0354 - accuracy: 0.9948"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "FKBewn4jYoLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "5KnWh2wShNzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy over Epochs')"
      ],
      "metadata": {
        "id": "U3cN46CaiQAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images, _ = next(test_generator)\n",
        "\n",
        "# Generar predicciones en el conjunto de datos de prueba\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "# Obtener las etiquetas reales y predichas\n",
        "true_labels = test_generator.classes\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Mostrar las imágenes con etiquetas reales y predichas\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(8):  # Muestra las primeras 16 imágenes\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(sample_images[i]/255)\n",
        "    plt.title(f\"True: {class_labels[true_labels[i]]}\\nPredicted: {class_labels[predicted_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Ajusta el espacio vertical y horizontal entre subgráficos\n"
      ],
      "metadata": {
        "id": "WeCKlCyJksYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Generar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(conf_matrix)\n",
        "# Obtener etiquetas de clases para visualización\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Crear un mapa de calor para visualizar la matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FpCQjrx7lelR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajuste de modelo"
      ],
      "metadata": {
        "id": "H-opFU3B04dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ajusted = tensorflow.keras.models.Sequential()\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "model_ajusted.add(base_model)\n",
        "model_ajusted.add(Dropout(0.5))\n",
        "model_ajusted.add(Flatten())\n",
        "model_ajusted.add(BatchNormalization())\n",
        "model_ajusted.add(Dropout(0.5))\n",
        "model_ajusted.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "d6UAbAr305-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ajusted.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DZgqCTCn1J1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(verbose = 1,\n",
        "                               patience = 5,)\n",
        "epochs = 100\n",
        "history_ajusted = model_ajusted.fit(\n",
        "    train_generator,\n",
        "    verbose = 1,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "id": "wpv7VbKX1NIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ajusted.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "LdytTo6T39Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_ajusted.history['loss'], label='Training Loss')\n",
        "plt.plot(history_ajusted.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_ajusted.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_ajusted.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy over Epochs')"
      ],
      "metadata": {
        "id": "4maFiwhM6wI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images, _ = next(test_generator)\n",
        "\n",
        "# Generar predicciones en el conjunto de datos de prueba\n",
        "predictions = model_ajusted.predict(test_generator)\n",
        "\n",
        "# Obtener las etiquetas reales y predichas\n",
        "true_labels = test_generator.classes\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Mostrar las imágenes con etiquetas reales y predichas\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(8):  # Muestra las primeras 16 imágenes\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(sample_images[i]/255)\n",
        "    plt.title(f\"True: {class_labels[true_labels[i]]}\\nPredicted: {class_labels[predicted_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Ajusta el espacio vertical y horizontal entre subgráficos\n"
      ],
      "metadata": {
        "id": "YEy8HeM631I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Generar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(conf_matrix)\n",
        "# Obtener etiquetas de clases para visualización\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Crear un mapa de calor para visualizar la matriz de confusión\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O4czO1PU3xRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}